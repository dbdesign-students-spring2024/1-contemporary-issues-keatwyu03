```markdown
# Two articles that have opposing viewpoints on the use of generative AI on data and data security
<br/>In this document, I will be exploring two different opinions about the use of generative AI on data security. As generative AI has become one of the largest breakthroguhs recently, speculations about its use arises. Some say that generative AI can yield to breaches in our sensitive data, making them susceptible to data brokers. Whereas others, belive that as long as ethical regulations are set in place to oversee the usage of generative AI, it will not infringe on data security at all. <br/>

## Article 1<br/>
In fast company's article [Companies are struggling to keep private data safe from generative AI, Cisco says](https://www.fastcompany.com/91016367/companies-are-struggling-to-keep-private-data-safe-from-generative-ai-cisco-says) by Issie Lapowsky, we get a major red flag about generative AI and how it may potentially breach data securtiy norms. As stated in the article, there are majority numbers in a privacy poll on secutiy professionals who fear, and to some extent even ask for a ban, the use of generative AI on their data. With the growing concern, may companies have, in response, released products that claim to prevent the removal of sensitive data from being susceptible to data breaches by generative AI. This struggle to prevent data from being accessed by the outside has always been prevalent, whether that is prevention from automated generative AI or just data brokers. OpenAI launched a Chatbot option that furthered the realm of generative AI, and it completely makes sense that the growing concerns about how generative AI or chat bots can limit the usage of private or sensitive data. <br/>

<br/>The majority concern that people have with generative AI, according to the article, is not with its implementation, but rather how the models are trained. Experts say that these AI programs are trained with public data, that might be proprietary to individuals or businesses. And this very scary. In the past, when there were no patents or liscenses to produce products, copying technology was commonplace. But once the patent laws were put in place to protect creators, then copying technology or parts become seldom. I believe that the same will be needed for generative AI and its training models. A not so cost friendly solution would be to work with individual businesses to extract data that is not sensitive or private to the company. But there  should and will be solutions that need to be implemented in order to bostler the growth of AI and technology. <br/>

## Article 2<br/>
In another article [How Generative AI Can Help Lower Data Risk in Enterprises](https://insidebigdata.com/2024/01/25/how-generative-ai-can-help-lower-data-risk-in-enterprises/) we see different viewpoint to what Lapowsky has stated. It seems like the much so feared generative AI, conversely, is being used as part of a general counteractive measure to prevent data leakage and in turn protect data. This measure, as stated in the article, is to use a transformation of generative data that allows business to directly interact with their customers. But, the author does also bring up ethical policies that should be adhered to when running generative AI programs. Another benefit that is addressed by the article that can help protect data is using generative AI to improve **"organizational effectiveneess"**. This may not be a derivative of the generative AI that has been widely researched or implemented, but having a stronger structure to enhance customer data security and hence experience is important to each company. <br/>

<br/>The main difference, and the point of contention between the two articles, is whether or not generative AI infringes on the privacy of our data. In the former, many examples are proposed to show that generative AI has already breached public data systems for personal use. But in this article, a more sanguine approach to the development in generative AI and data security - a stance that I would affirm. In ever turn of the decade, a new piece of technology is being produced, and it is fairly normal that we see skepticism in its safe implementation. In our data sensitive society now, the points that Lapowsky addresses is crucial to seeing generative AI and data security coexist. And it is only when businesses, individuals, and governments come up with a set of regulations that define the safe usage of AI and protect everyone's data. Then it comes down to consistent strengthning of procedures of generative AI that will hopefully resolve the pessimism. I personally have faith in generative AI finding the balance that it needs to become not only a powerful source of technological advancement, but also a safe tool to gather and store our personal or business data - it really is only a matter of time. <br/>

```